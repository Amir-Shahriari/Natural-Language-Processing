{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f418448a-82ec-45d7-b23a-c66709f4a4fe",
   "metadata": {},
   "source": [
    "# Amir Hossein Shahriari 45747067\n",
    "## COMP8420\n",
    "### Assignment1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afddf896-0211-44ba-b540-cc98f89f7e65",
   "metadata": {},
   "source": [
    "#### Imported libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a2b187-de80-47da-8128-dde49283db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b01b24-7826-4896-9659-bce2118321d8",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbdce08-d5f0-47e3-b026-742d844e95eb",
   "metadata": {},
   "source": [
    "for this task i will use a dataset from HuggingFace, the link to the data set is https://huggingface.co/datasets/shahxeebhassan/human_vs_ai_sentences, the dataset includes two columns, text and label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa578350-fe3c-4708-9787-9f80a533abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"shahxeebhassan/human_vs_ai_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148df4b2-cd4b-4fa3-85e3-d13d86cf33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 105000\n",
      "    })\n",
      "})\n",
      "{'text': 'Another reason why all students should have to participate in at least one extracurricular activity is because it develops stronger social skills.', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(ds)\n",
    "print(ds['train'][0])  # Look at a sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879d2a1d-67ba-4e55-9f8c-28272cf26838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Another reason why all students should have to...      0\n",
      "1  Also the Electoral College consists of 538 ele...      0\n",
      "2  Many countries have made changes in there town...      0\n",
      "3  I believe the process of choosing a president ...      0\n",
      "4  A thick cloud of carbon dioxide and heats to h...      0\n",
      "                                                    text  label\n",
      "10000  If people only feel comfortable around people ...      1\n",
      "10001  On the other hand, it can lead to stress and b...      1\n",
      "10002  The residents of all regions can feel that the...      1\n",
      "10003  Because many connected products still lack bas...      1\n",
      "10004  They can give you advice on how to set goals a...      1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert dataset to a pandas DataFrame for convenience:\n",
    "df = ds['train'].to_pandas()\n",
    "# Printing 5 rows of each label to see how they look\n",
    "print(df[df['label']==0].head())\n",
    "print(df[df['label']==1].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ec9a9-aef3-4630-ab3a-df44119e4eb8",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c372cf-98fc-46e0-97ce-92ca15f12a74",
   "metadata": {},
   "source": [
    "In this part I will preprocess the data by converting to lowercase, removing special characters/punctuation, and optionally stop words. Furthermore I will split the collected data into train, test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d5c001-939e-4b19-bb7d-a935ba068fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want 60% train, 20% validation, 20% test\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "# 1. Defining a custom preprocessing function\n",
    "def custom_preprocessor(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and punctuation (leaving alphanumeric and whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # (Optional) You could remove numeric characters or extra whitespace if needed:\n",
    "    # text = re.sub(r'\\d+', '', text)\n",
    "    # text = \" \".join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 2. (Optional) Use a custom tokenizer\n",
    "#    In many cases, TfidfVectorizer will handle tokenization, but you can override it if desired:\n",
    "# def custom_tokenizer(text):\n",
    "#     # Example: split on whitespace\n",
    "#     return text.split()\n",
    "\n",
    "# 3. Set up TF-IDF with your custom preprocessor (and optional custom tokenizer)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    preprocessor=custom_preprocessor,\n",
    "    stop_words='english'  # optional built-in stop-word removal\n",
    "    # tokenizer=custom_tokenizer  # if you want a custom tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "X_train = tfidf.fit_transform(train_df['text']).toarray()\n",
    "y_train = train_df['label'].values\n",
    "\n",
    "X_val = tfidf.transform(val_df['text']).toarray()\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "X_test = tfidf.transform(test_df['text']).toarray()\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Now X_train, X_val, X_test contain the TF-IDF features of preprocessed text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch GPU Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
